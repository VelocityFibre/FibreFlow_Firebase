# Neon Database Integration for FibreFlow

## Overview
This directory contains all Neon-related configurations, scripts, and documentation for FibreFlow's PostgreSQL analytics database.

## Purpose
Neon is being integrated as a PostgreSQL-based alternative/complement to Supabase for:
- Complex SQL analytics and reporting
- Time-series data analysis
- Cross-table JOINs and aggregations
- Data warehousing capabilities
- Advanced querying that's difficult with Firestore

## Why Neon for AI Agents
**In summary, for AI agents focused on querying data and answering user queries, Neon provides a more optimized, cost-effective experience for high-velocity, agent-driven tasks, as backed by adoption stats and developer feedback. Supabase is a strong alternative if your agents need realtime sync or auth for user interactions.**

Key advantages for AI/agent workloads:
- **Optimized for read-heavy queries** - Perfect for analytics and reporting
- **Cost-effective** - Pay-per-use model ideal for sporadic agent queries
- **High velocity** - Built for rapid query execution
- **Developer-friendly** - Simple PostgreSQL without extra abstractions
- **Serverless scaling** - Auto-scales with agent demand

## Architecture Decision
FibreFlow uses a **hybrid database architecture**:
1. **Firebase Firestore** - Primary database for real-time operations, CRUD, authentication
2. **Neon PostgreSQL** - Analytics database for complex queries, reporting, and data analysis

### Multi-Database Architecture (Updated 2025-01-30)

**Clear Separation of Concerns**:
- **Firebase**: Field operations, photos, offline sync, real-time updates
- **Neon**: Excel imports (SOW/OneMap), analytics, status tracking
- **Staging** (planned): Data validation, duplicate checking, quality gates

**No Duplication Policy**:
- Photos stay in Firebase only
- Status/analytics in Neon only
- Each data type has ONE home

**Data Flow**:
```
Field App â†’ Staging â†’ Firebase (photos, GPS, real-time)
Excel Imports â†’ Staging â†’ Neon (analytics, status, reports)
                â†“
           FibreFlow UI (reads both)
```

For complete architecture documentation, see:
- `MULTI_DATABASE_ARCHITECTURE.md` (in this directory)
- `/dbase/MULTI_DATABASE_ARCHITECTURE_WITH_STAGING.md` (staging layer details)

## Connection Details
- **Host**: ep-long-breeze-a9w7xool-pooler.gwc.azure.neon.tech
- **Database**: neondb
- **User**: neondb_owner
- **Connection String**: `postgresql://neondb_owner:npg_AlX83ojfZpBk@ep-long-breeze-a9w7xool-pooler.gwc.azure.neon.tech/neondb?sslmode=require`
- **Region**: Azure GWC (Great Western Canada)
- **Pooler**: Connection pooling enabled for better performance

## Directory Structure
```
Neon/
â”œâ”€â”€ CLAUDE.md           # This file - main documentation
â”œâ”€â”€ docs/               # Additional documentation
â”‚   â”œâ”€â”€ setup.md        # Setup instructions
â”‚   â”œâ”€â”€ migration.md    # Migration guide from Supabase
â”‚   â””â”€â”€ queries.md      # Common query patterns
â”œâ”€â”€ scripts/            # Utility scripts
â”‚   â”œâ”€â”€ sync-data.js    # Sync data from Firestore to Neon
â”‚   â”œâ”€â”€ test-connection.js # Test Neon connection
â”‚   â””â”€â”€ migrate-tables.js  # Table migration scripts
â”œâ”€â”€ sql/                # SQL files
â”‚   â”œâ”€â”€ schema.sql      # Database schema
â”‚   â”œâ”€â”€ indexes.sql     # Performance indexes
â”‚   â””â”€â”€ views.sql       # Analytical views
â””â”€â”€ config/             # Configuration files
    â””â”€â”€ tables.json     # Table definitions
```

## Key Features
- **Serverless**: Auto-suspend when inactive (cost-efficient)
- **Branching**: Create database branches for testing
- **Point-in-time Recovery**: Restore to any point in the last 7 days
- **Connection Pooling**: Built-in PgBouncer for better performance
- **PostgreSQL 16**: Latest PostgreSQL features

## Integration Status âœ… COMPLETED
- [x] Neon project created
- [x] Connection string added to environment
- [x] NeonService created
- [x] npm packages installed
- [x] Test connection established
- [x] Schema created
- [x] **FULL DATA SYNC COMPLETED** - 15,651 rows from Supabase
- [x] Analytics queries ready for testing

## Usage in FibreFlow

### For Analytics Queries
```typescript
// Example: Get project completion rates by zone
const analytics = await neonService.query(`
  SELECT 
    zone,
    COUNT(*) as total_projects,
    SUM(CASE WHEN status = 'completed' THEN 1 ELSE 0 END) as completed,
    ROUND(AVG(progress), 2) as avg_progress
  FROM projects
  GROUP BY zone
  ORDER BY avg_progress DESC
`);
```

### For Complex Reporting
```typescript
// Example: Time-series analysis of daily progress
const timeSeries = await neonService.query(`
  SELECT 
    DATE_TRUNC('day', created_at) as date,
    COUNT(DISTINCT project_id) as active_projects,
    SUM(poles_installed) as daily_poles,
    SUM(drops_connected) as daily_drops
  FROM daily_progress
  WHERE created_at >= NOW() - INTERVAL '30 days'
  GROUP BY date
  ORDER BY date
`);
```

## Security Considerations
- Connection string contains credentials - NEVER commit to git
- Use environment variables for production
- Enable Row Level Security (RLS) for sensitive data
- Use read-only roles for analytics queries

## Performance Tips
- Use connection pooling (already enabled via pooler URL)
- Create indexes on frequently queried columns
- Use materialized views for complex analytics
- Partition large tables by date/time

## Comparison with Supabase
| Feature | Supabase | Neon |
|---------|----------|------|
| Database | PostgreSQL 15 | PostgreSQL 16 |
| Pricing | Fixed tiers | Pay-per-use |
| Branching | Limited | Full branching |
| Serverless | Partial | Full serverless |
| Connection Pooling | PgBouncer | Built-in pooler |
| Point-in-time Recovery | 7 days (Pro) | 7 days (all plans) |

## Next Steps
1. Install PostgreSQL client packages (@neondatabase/serverless)
2. Create NeonService for database operations
3. Set up initial schema
4. Implement data sync from Firestore
5. Migrate analytics queries from Supabase

## Related Files
- `/src/app/core/services/neon.service.ts` - Neon service (to be created)
- `/src/environments/environment.prod.ts` - Contains connection string
- `/src/app/core/types/environment.types.ts` - Environment type definitions

## Important Documentation
- `docs/supabase-vs-neon-comparison.md` - **CRITICAL READ**: Analysis of why Supabase import failed vs Neon success
- `logs/import-processing-log.md` - Complete processing history of all Excel imports
- `scripts/analyze-overlap.js` - Proves Excel files contain 66% duplicate data across files

## ðŸš€ PROVEN WORKFLOW - Standard Operating Procedure

### âœ… SUCCESSFUL SYNC METHOD (Cloud-to-Cloud)
**Status**: TESTED AND WORKING - 100% sync success (15,651 rows)

```bash
# 1. Test Neon connection first
node Neon/scripts/test-connection.js

# 2. Fast batch sync (RECOMMENDED - PROVEN WORKING)
# Run multiple times until complete
node Neon/scripts/fast-batch-sync.js

# 3. Verify completion
psql 'postgresql://neondb_owner:npg_AlX83ojfZpBk@ep-long-breeze-a9w7xool-pooler.gwc.azure.neon.tech/neondb?sslmode=require&options=endpoint%3Dep-long-breeze-a9w7xool' -c "SELECT COUNT(*) FROM status_changes;"
```

### âœ… **NEW: EXCEL IMPORT WORKFLOW (2025-01-30)**
**Status**: PRODUCTION READY - Validated with real Excel files

```bash
# 1. Compare new Excel file with existing data (ALWAYS DO THIS FIRST)
node Neon/scripts/compare-excel-with-neon.js /path/to/file.xlsx

# 2. If changes detected, import them with tracking
node Neon/scripts/fast-excel-import.js /path/to/file.xlsx

# 3. View processing history and status changes
node Neon/scripts/view-import-batches.js

# 4. Log results in Neon/logs/import-processing-log.md
```

**Key Features:**
- **Smart comparison** - Only imports actual changes
- **Status tracking** - Complete history of all status changes  
- **Duplicate prevention** - Never creates duplicate records
- **Data validation** - Checks data integrity before import
- **Batch processing** - Handles large files efficiently

### ðŸ“‹ Complete Command Reference

#### Test & Verification
```bash
# Test connection
node Neon/scripts/test-connection.js

# Check current data status
psql 'postgresql://neondb_owner:npg_AlX83ojfZpBk@ep-long-breeze-a9w7xool-pooler.gwc.azure.neon.tech/neondb?sslmode=require&options=endpoint%3Dep-long-breeze-a9w7xool' -c "SELECT COUNT(*) as total_rows, ROUND(COUNT(*) * 100.0 / 15651, 1) as percentage FROM status_changes;"
```

#### CLOUD-TO-CLOUD SYNC OPTIONS (âœ… NO LOCAL BANDWIDTH)
```bash
# BEST PRACTICE - Fast incremental batch sync (PROVEN)
node Neon/scripts/fast-batch-sync.js

# Alternative - Smaller incremental batches
node Neon/scripts/incremental-sync.js

# Alternative - Data cleanup version
node Neon/scripts/sync-with-data-cleanup.js

# Resume from partial sync
node Neon/scripts/resume-sync.js
```

#### LOCAL SYNC OPTIONS (uses your WiFi bandwidth)
```bash
# Local PostgreSQL to Neon
./Neon/scripts/sync-local-postgres-to-neon.sh

# Using Node.js pg client
node Neon/scripts/sync-postgres-to-neon.js
```

#### Performance Testing
```bash
# Compare Supabase vs Neon performance
node Neon/scripts/compare-databases.js
```

## ðŸ“š LESSONS LEARNED - Standard Operating Procedure

### âœ… WHAT WORKS (Proven Methods)

#### 1. Cloud-to-Cloud Sync Strategy
- **NEVER use local bandwidth** for large datasets (>10k rows)
- **USE**: `fast-batch-sync.js` - Processes 1000 rows at ~80-100 rows/sec
- **RESULT**: 100% success rate, reliable, resumable

#### 2. Incremental Batch Processing
- **Batch Size**: 1000 rows (optimal for Neon/Supabase)
- **Strategy**: Resume from MAX(id) to avoid duplicates
- **Error Handling**: ON CONFLICT DO NOTHING for safe reruns
- **Progress Tracking**: Show percentage and ETA

#### 3. Data Quality Handling
- **Date Fields**: Clean invalid dates (e.g., "249111" â†’ null)
- **NULL Safety**: Handle undefined/null values properly
- **Type Detection**: Smart PostgreSQL type mapping from samples

#### 4. Connection Patterns
- **Neon**: Use pooler URL with endpoint parameter
- **Supabase**: Use public API keys for read operations
- **Postgres**: Always use SSL and connection pooling

### âŒ WHAT DOESN'T WORK (Avoid These)

#### 1. Row-by-Row Inserts
- **Problem**: Too slow (~3-5 rows/sec)
- **Result**: Takes hours for large datasets
- **Solution**: Always use bulk INSERT with VALUES (...)

#### 2. Local Network Sync
- **Problem**: Limited bandwidth, interruptions
- **Result**: Frequent timeouts, incomplete syncs
- **Solution**: Use cloud-to-cloud transfers only

#### 3. Complex Query Builders
- **Problem**: Tagged template literals syntax errors
- **Result**: Runtime failures, debugging complexity  
- **Solution**: Use simple parameterized queries

#### 4. Single Large Batch
- **Problem**: Memory issues, long transactions
- **Result**: Connection timeouts, rollbacks
- **Solution**: Process in 1000-row batches

### ðŸ”§ TROUBLESHOOTING GUIDE

#### Connection Issues
```bash
# Test Neon endpoint
psql 'postgresql://neondb_owner:npg_AlX83ojfZpBk@ep-long-breeze-a9w7xool-pooler.gwc.azure.neon.tech/neondb?sslmode=require&options=endpoint%3Dep-long-breeze-a9w7xool'

# If endpoint error: Add options parameter
&options=endpoint%3Dep-long-breeze-a9w7xool
```

#### Sync Issues  
```bash
# Check current progress
SELECT COUNT(*) as current, 15651 as target, 
       ROUND(COUNT(*) * 100.0 / 15651, 1) as percent_complete
FROM status_changes;

# Find missing ID ranges
SELECT MIN(id) as first_missing FROM (
  SELECT id + 1 as id FROM status_changes 
  EXCEPT SELECT id FROM status_changes
) t;
```

#### Performance Issues
```bash
# Create indexes for faster queries
CREATE INDEX idx_status_changes_property_id ON status_changes (property_id);
CREATE INDEX idx_status_changes_status ON status_changes (status);
CREATE INDEX idx_status_changes_created_at ON status_changes (created_at);
```

### ðŸ“Š Performance Benchmarks (Actual Results)

| Method | Speed | Reliability | Bandwidth | Best For |
|--------|-------|-------------|-----------|----------|
| fast-batch-sync.js | 80-100 rows/sec | âœ… 100% | âœ… Zero local | Production sync |
| incremental-sync.js | 50-70 rows/sec | âœ… 95% | âœ… Zero local | Cautious sync |
| Row-by-row | 3-5 rows/sec | âš ï¸ 60% | âœ… Zero local | Small datasets only |
| Local sync | Variable | âŒ 40% | âŒ High local | Avoid for >1k rows |

## Data Sources
- **Supabase Source**: 15,651 rows in `status_changes` table
- **Neon Destination**: 15,651 rows synced successfully âœ…
- **Sync Success Rate**: 100% with cloud-to-cloud approach
- **Purpose**: Compare Neon vs Supabase for analytics workloads

## Important Notes
- This is a pooled connection (note the `-pooler` in hostname)
- The `channel_binding=require` parameter was removed as it's not needed with pooled connections
- Always use SSL (sslmode=require) for security
- The database will auto-suspend after 5 minutes of inactivity (free tier)

---

*Last Updated: 2025-01-30*
*Status: Initial Setup Phase*